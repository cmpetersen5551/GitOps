---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: seaweedfs
  namespace: seaweedfs
spec:
  interval: 1h
  chart:
    spec:
      chart: seaweedfs
      version: ">=3.0.0"
      sourceRef:
        kind: HelmRepository
        name: seaweedfs
        namespace: seaweedfs
  values:
    # Global settings
    global:
      replicationPlacement: "010"  # 1 replica on different rack/zone
      imageName: chrislusf/seaweedfs
      imageTag: "latest"
      imagePullPolicy: IfNotPresent
      enableSecurity: false
      monitoring:
        enabled: false
    
    # Master configuration (consensus layer)
    master:
      enabled: true
      replicas: 3
      defaultReplication: "010"
      volumeSizeLimitMB: 1024
      
      # Resource configuration
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
      
      # Data persistence for Raft consensus
      data:
        type: "persistentVolumeClaim"
        size: "2Gi"
        storageClass: "local-path"
    
    # Disable single volume configuration (we use volumes: plural)
    volume:
      enabled: false
    
    # Multi-zone volume server configuration with rack/datacenter topology
    volumes:
      # Proxmox zone - 2 volume servers (k3s-w1, k3s-w3)
      proxmox:
        enabled: true
        replicas: 2
        dataCenter: "dc1"
        rack: "proxmox"
        
        # Resource configuration
        resources:
          requests:
            cpu: 250m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        
        # Node selector to pin to proxmox zone (as string, not object)
        nodeSelector: |
          topology.kubernetes.io/zone: proxmox
          sw-volume: "true"
        
        # Tolerate GPU taint on k3s-w3 (as string, not object)
        tolerations: |
          - key: gpu
            operator: Equal
            value: "true"
            effect: NoSchedule
        
        # Data directories configuration
        dataDirs:
          - name: data
            type: "persistentVolumeClaim"
            size: "100Gi"
            storageClass: "local-path"
            maxVolumes: 100
      
      # Unraid zone - 1 volume server (k3s-w2)
      unraid:
        enabled: true
        replicas: 1
        dataCenter: "dc1"
        rack: "unraid"
        
        # Resource configuration
        resources:
          requests:
            cpu: 250m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        
        # Node selector to pin to unraid zone (as string, not object)
        nodeSelector: |
          topology.kubernetes.io/zone: unraid
          sw-volume: "true"
        
        # Data directories configuration
        dataDirs:
          - name: data
            type: "persistentVolumeClaim"
            size: "100Gi"
            storageClass: "local-path"
            maxVolumes: 100
    
    # Filer configuration (filesystem metadata layer)
    filer:
      enabled: true
      replicas: 1
      defaultReplicaPlacement: "010"
      
      # Resource configuration
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
      
      # Filer configuration (LevelDB for now)
      config: |
        [leveldb2]
        enabled = true
        dir = "/data/filerldb2"
      
      # S3 API enablement
      s3:
        enabled: true
        enableAuth: false
      
      # Data persistence for filer metadata
      data:
        type: "persistentVolumeClaim"
        size: "2Gi"
        storageClass: "local-path"
